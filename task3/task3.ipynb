{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "task3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDBm2rHfWOTq"
      },
      "source": [
        "Task 3<br>\n",
        "<ol>\n",
        "<li>Create custom dataloader\n",
        "<li>Custom CNN\n",
        "<li>Custom training and evaluation function\n",
        "</ol>\n",
        "\n",
        "Data can be found at \n",
        "<a href=\"https://drive.google.com/file/d/1c9R_WO0ttNFSYXLG7Zap0ToBASLLq6Rb/view?usp=sharing\">here</a>\n",
        "\n",
        "As a label to our data, we ought to use action field<br>"
      ],
      "id": "qDBm2rHfWOTq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp4vbMkzWP6P"
      },
      "source": [
        "First import the python tools"
      ],
      "id": "Hp4vbMkzWP6P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4a8548d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "\n",
        "from os import *\n",
        "import random\n",
        "from torch.utils.data import Dataset"
      ],
      "id": "f4a8548d",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2hZAxpzWaJK"
      },
      "source": [
        "Here I define all labels for fields in dataset\n",
        "Code below was provided by my college "
      ],
      "id": "_2hZAxpzWaJK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c456fd1b"
      },
      "source": [
        "classes = [\n",
        "        'frame_num', \n",
        "        'action', \n",
        "        'team_controlling_ball', \n",
        "        'ball_x', \n",
        "        'ball_y', \n",
        "        'num_players_team1', \n",
        "        'num_players_team2', \n",
        "        'scene', \n",
        "        'no_team1_players',\n",
        "    ]\n",
        "\n",
        "\n",
        "for i in range(11):\n",
        "    classes.append('team1_player' + str(i) + 'x')\n",
        "    classes.append('team1_player' + str(i) + 'y')\n",
        "\n",
        "classes.append('no_team1_players')\n",
        "\n",
        "for i in range(11):\n",
        "    classes.append('team2_player' + str(i) + 'x')\n",
        "    classes.append('team2_player' + str(i) + 'y')"
      ],
      "id": "c456fd1b",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQDy31ozXEMZ"
      },
      "source": [
        "Define custom dataloader "
      ],
      "id": "eQDy31ozXEMZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21c4a35"
      },
      "source": [
        "class my_dataloader(Dataset):\n",
        "        def __init__(self, input_file):\n",
        "            \n",
        "            dataset = np.load(input_file)\n",
        "            self.length = len(dataset) - 1\n",
        "            \n",
        "            try:\n",
        "                mkdir(\"data\")\n",
        "            except:\n",
        "                print(\"Out folder arledy exists skiping\")\n",
        "                return\n",
        "            \n",
        "            i = 0\n",
        "            for data in dataset:\n",
        "                file = \"./data/\"+ str(i) + \".npy\"\n",
        "                np.save(file, data)\n",
        "                i+=1\n",
        "        \n",
        "        def __len__(self):\n",
        "            return self.length\n",
        "        \n",
        "        def __getitem__(self, i):\n",
        "            if i == self.length:\n",
        "                return StopIteration\n",
        "            train = np.load(\"./data/\"+str(random.randint(0, self.length))+\".npy\")\n",
        "            train_data = [(float(train[3])),(float(train[4]))]\n",
        "            train_data = np.array([train_data],dtype=np.float32)\n",
        "            train_data = torch.from_numpy(train_data)\n",
        "            train_labels = torch.from_numpy(np.array([int(train[1])]))\n",
        "            return train_data, train_labels"
      ],
      "id": "f21c4a35",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2zq56p5XHR5"
      },
      "source": [
        "load data from file"
      ],
      "id": "V2zq56p5XHR5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "3451a34c",
        "outputId": "24bca08e-e219-41ef-85af-80aefea17ec5"
      },
      "source": [
        "data_loader = my_dataloader(\"./data.npy\")"
      ],
      "id": "3451a34c",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-41c8f3fee388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-7e9db5ff7cb2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbefh-mnXcGB"
      },
      "source": [
        "My custom neural net class, \n",
        "copied from assigment 2 "
      ],
      "id": "Mbefh-mnXcGB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb947493"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lay1 = nn.Linear(2,20)\n",
        "        self.lay2 = nn.Linear(20,20)\n",
        "        self.lay3 = nn.Linear(20,41)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        x = f.relu(self.lay1(x))\n",
        "        x = f.relu(self.lay2(x))\n",
        "        \n",
        "        return self.lay3(x)\n",
        "\n",
        "net = Net()"
      ],
      "id": "fb947493",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NCWmG4hXhuP"
      },
      "source": [
        "define optimizer and loss function"
      ],
      "id": "1NCWmG4hXhuP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed05b8b3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "id": "ed05b8b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDacJM7tXngp"
      },
      "source": [
        "main loop, here I feed data to my neural net,<br>\n",
        "and calculate the resolut  \n",
        "\n"
      ],
      "id": "DDacJM7tXngp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7513f301"
      },
      "source": [
        "losses = []\n",
        "i = 1\n",
        "current_loss = 0\n",
        "for chunk in data_loader:\n",
        "    train_data, train_label = chunk\n",
        "    optimizer.zero_grad()\n",
        "    guess = net(train_data)\n",
        "    loss = criterion(guess.view(1,41), train_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    current_loss += loss.item()\n",
        "    i += 1\n",
        "    \n",
        "    if i == 2000:\n",
        "        print(\"Current loss: \" + str(current_loss / 2000))\n",
        "        losses.append(current_loss/2000)\n",
        "        current_loss = 0\n",
        "        i = 0"
      ],
      "id": "7513f301",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn69VH4OX8fv"
      },
      "source": [
        "plot loss funtion"
      ],
      "id": "hn69VH4OX8fv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39437a11"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "id": "39437a11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUIGBg3OX_FW"
      },
      "source": [
        "calculate final error"
      ],
      "id": "PUIGBg3OX_FW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872740a1"
      },
      "source": [
        "correct = 0  \n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(data_loader): \n",
        "        images, labels = data\n",
        "        images = images\n",
        "        labels = labels\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size()[0]\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "print(\"End accuracy: \", correct/total)"
      ],
      "id": "872740a1",
      "execution_count": null,
      "outputs": []
    }
  ]
}